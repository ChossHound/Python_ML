{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor, Compose, Resize, Normalize\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, StratifiedGroupKFold\n",
    "from torch.utils.data import Subset\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_DIR = \"data\"\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "IMG_SIZE = (128, 128)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "N_SPLITS = 5  # Number of folds for cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations\n",
    "transform = Compose([\n",
    "    Resize(IMG_SIZE),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Pooling layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Calculate the size after convolutions and pooling\n",
    "        # Input size: IMG_SIZE[0] x IMG_SIZE[1]\n",
    "        # After first conv+pool: IMG_SIZE[0]/2 x IMG_SIZE[1]/2\n",
    "        # After second conv+pool: IMG_SIZE[0]/4 x IMG_SIZE[1]/4\n",
    "        conv_output_size = 32 * (IMG_SIZE[0] // 4) * (IMG_SIZE[1] // 4)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(conv_output_size, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # -> [B, 16, IMG_SIZE[0]/2, IMG_SIZE[1]/2]\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # -> [B, 32, IMG_SIZE[0]/4, IMG_SIZE[1]/4]\n",
    "        x = x.view(x.size(0), -1)             # flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple CNN Model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, \n",
    "                      kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * (IMG_SIZE[0] // 4) * (IMG_SIZE[1] // 4), 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jjalonzo-estra/miniconda3/envs/Jotun/lib/python3.12/site-packages/PIL/Image.py:981: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 3.4581\n",
      "Epoch [2/10], Loss: 2.1563\n",
      "Epoch [3/10], Loss: 1.5103\n",
      "Epoch [4/10], Loss: 1.0013\n",
      "Epoch [5/10], Loss: 0.6176\n",
      "Epoch [6/10], Loss: 0.3970\n",
      "Epoch [7/10], Loss: 0.2776\n",
      "Epoch [8/10], Loss: 0.2277\n",
      "Epoch [9/10], Loss: 0.1864\n",
      "Epoch [10/10], Loss: 0.1650\n",
      "Fold 1 Results:\n",
      "Validation Loss: 4.0888\n",
      "Validation Accuracy: 51.19%\n",
      "F1 Score: 0.5132\n",
      "\n",
      "Fold 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jjalonzo-estra/miniconda3/envs/Jotun/lib/python3.12/site-packages/PIL/Image.py:981: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load full dataset\n",
    "dataset = ImageFolder(root=DATA_DIR, transform=transform)\n",
    "\n",
    "# Get indices and labels for stratified split\n",
    "indices = list(range(len(dataset)))\n",
    "labels = [dataset.targets[i] for i in indices]\n",
    "# train_indices, test_indices = train_test_split(indices, train_size=0.8, stratify=labels, random_state=42)\n",
    "\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store metrics for each fold\n",
    "fold_metrics = []\n",
    "\n",
    "# Training and evaluation for each fold\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(indices, labels)):\n",
    "    print(f\"\\nFold {fold + 1}/{N_SPLITS}\")\n",
    "    \n",
    "    # Create data loaders for this fold\n",
    "    train_subsampler = Subset(dataset, train_idx)\n",
    "    val_subsampler = Subset(dataset, val_idx)\n",
    "    \n",
    "    train_loader = DataLoader(train_subsampler, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_subsampler, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    # Initialize model for this fold\n",
    "    num_classes = len(dataset.classes)\n",
    "    model = SimpleCNN(num_classes=num_classes).to(DEVICE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Training loop (your existing training code)\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{EPOCHS}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "    \n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics for this fold\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    # Store metrics for this fold\n",
    "    fold_metrics.append({\n",
    "        'fold': fold + 1,\n",
    "        'running_loss': running_loss/len(train_loader),\n",
    "        'val_loss': avg_val_loss,\n",
    "        'val_accuracy': accuracy,\n",
    "        'f1_score': f1\n",
    "    })\n",
    "    \n",
    "    print(f\"Fold {fold + 1} Results:\")\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "    print(f\"Validation Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Convert metrics to DataFrame\n",
    "metrics_df = pd.DataFrame(fold_metrics)\n",
    "\n",
    "# Add mean and std of metrics\n",
    "mean_metrics = metrics_df.mean()\n",
    "std_metrics = metrics_df.std()\n",
    "\n",
    "print(\"\\nCross-validation Results:\")\n",
    "print(f\"Average Loss: {mean_metrics['val_loss']:.4f} ± {std_metrics['val_loss']:.4f}\")\n",
    "print(f\"Average Accuracy: {mean_metrics['val_accuracy']:.2f}% ± {std_metrics['val_accuracy']:.2f}%\")\n",
    "print(f\"Average F1 Score: {mean_metrics['f1_score']:.4f} ± {std_metrics['f1_score']:.4f}\")\n",
    "\n",
    "# Save metrics to CSV\n",
    "try:\n",
    "    existing_df = pd.read_csv('model_metrics.csv')\n",
    "    metrics_df = pd.concat([existing_df, metrics_df], ignore_index=True)\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "metrics_df.to_csv('model_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artifact\n",
    "# # Load full dataset\n",
    "# dataset = ImageFolder(root=DATA_DIR, transform=transform)\n",
    "\n",
    "# # Get indices and labels for stratified split\n",
    "# indices = list(range(len(dataset)))\n",
    "# labels = [dataset.targets[i] for i in indices]\n",
    "# # Create subset of dataset\n",
    "# train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# test_dataset = torch.utils.data.Subset(dataset, test_indices)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize model\n",
    "# num_classes = len(dataset.classes)\n",
    "# model = CNN(num_classes=num_classes).to(DEVICE)\n",
    "\n",
    "# # Loss and optimizer\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training loop\n",
    "# for epoch in range(1):\n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "#     for images, labels in train_loader:\n",
    "#         images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "#         outputs = model(images)\n",
    "#         loss = criterion(outputs, labels)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         running_loss += loss.item()\n",
    "\n",
    "#     print(f\"Epoch [{epoch+1}/{EPOCHS}], Loss: {running_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing loop\n",
    "# model.eval()  # Set model to evaluation mode\n",
    "# test_loss = 0.0\n",
    "# correct = 0\n",
    "# total = 0\n",
    "\n",
    "# with torch.no_grad():  # Disable gradient computation for testing\n",
    "#     for images, labels in test_loader:\n",
    "#         images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        \n",
    "#         outputs = model(images)\n",
    "#         loss = criterion(outputs, labels)\n",
    "        \n",
    "#         test_loss += loss.item()\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# # Calculate and print test metrics\n",
    "# avg_test_loss = test_loss / len(test_loader)\n",
    "# accuracy = 100 * correct / total\n",
    "\n",
    "# # Calculate F1 score\n",
    "\n",
    "# f1 = f1_score(labels.cpu().numpy(), predicted.cpu().numpy(), average='weighted')\n",
    "\n",
    "# print(f\"Test Loss: {avg_test_loss:.4f}\")\n",
    "# print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "# print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a dictionary to store metrics\n",
    "# metrics = {\n",
    "#     'running_loss': running_loss/len(train_loader),\n",
    "#     'test_loss': avg_test_loss,\n",
    "#     'test_accuracy': accuracy,\n",
    "#     'f1_score': f1\n",
    "# }\n",
    "\n",
    "# # Convert to DataFrame and save to CSV\n",
    "# import pandas as pd\n",
    "# metrics_df = pd.DataFrame([metrics])\n",
    "\n",
    "# # Check if file exists and append or create new\n",
    "# try:\n",
    "#     existing_df = pd.read_csv('model_metrics.csv')\n",
    "#     metrics_df = pd.concat([existing_df, metrics_df], ignore_index=True)\n",
    "# except FileNotFoundError:\n",
    "#     pass\n",
    "\n",
    "# metrics_df.to_csv('model_metrics.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Jotun",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
